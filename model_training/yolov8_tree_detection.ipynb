{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "9Zf9a0SPLxPk",
        "outputId": "d1641d20-78d1-40c9-e9d9-6f4698475e74"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install onnx -q\n",
        "!pip install onnxruntime -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "X0RnA8O_T-o5",
        "outputId": "6a208040-f579-47e7-b453-c257be465552"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZstKUnh-LzwN",
        "outputId": "b37b9ef7-ddef-4fe9-d6f5-bb4e72b4b8f9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9L8OkdgOMNUs"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SLpRBKvCL1Mx"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/tree.v2i.yolov8/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o74OPRaoMXjR",
        "outputId": "82c74714-a695-413b-b582-3ca63e6721fb"
      },
      "outputs": [],
      "source": [
        "%ls /content/drive/MyDrive/tree.v2i.yolov8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAluO6M3MIF5",
        "outputId": "acfde377-30a0-4347-bf82-df9bc476b583"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "ozz-kGx4MmvJ",
        "outputId": "a16ae9c6-b639-403a-cd2f-73706db99ff4"
      },
      "outputs": [],
      "source": [
        "img0_path = path+'train/images/'\n",
        "img0_path = img0_path + os.listdir(img0_path)[0]\n",
        "img = cv2.imread(img0_path)\n",
        "print(img.shape)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okqf6Q2sM-3F",
        "outputId": "857fb65b-e307-4b6b-e353-3ae033c087d7"
      },
      "outputs": [],
      "source": [
        "train_results = model.train(\n",
        "    data=path+'/data.yaml',\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    device='cuda'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "QVZxTtohPo-4",
        "outputId": "225dbfa4-e3e1-4975-de48-bf2d06b563e7"
      },
      "outputs": [],
      "source": [
        "img = 'download1.jpeg'\n",
        "img = cv2.imread(img)\n",
        "# img = cv2.resize(img, (640,640))\n",
        "results = model(img)\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Extract bounding boxes\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get coordinates of the box\n",
        "        confidence = box.conf[0]  # Get confidence score\n",
        "        label = int(box.cls[0])  # Get the class label\n",
        "\n",
        "        # Draw bounding box on the image\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Add label and confidence score\n",
        "        cv2.putText(img, f'{model.names[label]} {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "LloZ5ljfTHmu",
        "outputId": "40d2f1b6-c20a-4c98-c98e-4d3a65b7bfdf"
      },
      "outputs": [],
      "source": [
        "model.export(format='onnx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRQOMgTEzDT8"
      },
      "source": [
        "**Next code is used to inference from onnx format**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJnKkS5zAuv"
      },
      "outputs": [],
      "source": [
        "# Ultralytics YOLO ðŸš€, AGPL-3.0 license\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "CLASSES = ['tree']\n",
        "colors = [(0, 123, 255)]\n",
        "\n",
        "\n",
        "def main(onnx_model, input_image, img_size):\n",
        "    model = cv2.dnn.readNetFromONNX(onnx_model)\n",
        "\n",
        "    original_image = cv2.imread(input_image)\n",
        "    height, width, _ = original_image.shape\n",
        "\n",
        "    # Prepare a square image for inference\n",
        "    length = max((height, width))\n",
        "    image = np.zeros((length, length, 3), np.uint8)\n",
        "    image[0:height, 0:width] = original_image\n",
        "    # image = cv2.resize(original_image, (img_size, img_size))\n",
        "\n",
        "    # Calculate scale factor\n",
        "    scale = length / img_size\n",
        "\n",
        "    # Preprocess the image and prepare blob for model\n",
        "    blob = cv2.dnn.blobFromImage(image, scalefactor=1 / 255, size=(img_size, img_size), swapRB=True)\n",
        "    model.setInput(blob)\n",
        "\n",
        "    outputs = model.forward()\n",
        "    print(outputs.shape)\n",
        "\n",
        "    # Prepare output array\n",
        "    outputs = np.array([cv2.transpose(outputs[0])])\n",
        "    rows = outputs.shape[1]\n",
        "\n",
        "    boxes = []\n",
        "    scores = []\n",
        "    class_ids = []\n",
        "    print(outputs[0][0])\n",
        "\n",
        "    # Iterate through output to collect bounding boxes, confidence scores, and class IDs\n",
        "    maxClassIndex = 0\n",
        "    for i in range(rows):\n",
        "        # classes_scores = outputs[0][i][4:]\n",
        "        # (minScore, maxScore, minClassLoc, (x, maxClassIndex)) = cv2.minMaxLoc(classes_scores)\n",
        "        maxScore = outputs[0][i][4]\n",
        "\n",
        "        if maxScore >= 0.25:\n",
        "            box = [\n",
        "                outputs[0][i][0] - (0.5 * outputs[0][i][2]),\n",
        "                outputs[0][i][1] - (0.5 * outputs[0][i][3]),\n",
        "                outputs[0][i][2],\n",
        "                outputs[0][i][3],\n",
        "            ]\n",
        "            boxes.append(box)\n",
        "            scores.append(maxScore)\n",
        "            class_ids.append(maxClassIndex)\n",
        "\n",
        "    # Apply NMS (Non-maximum suppression)\n",
        "    result_boxes = cv2.dnn.NMSBoxes(boxes, scores, 0.25, 0.45, 0.5)\n",
        "\n",
        "    detections = []\n",
        "\n",
        "    # Iterate through NMS results to draw bounding boxes and labels\n",
        "    for i in range(len(result_boxes)):\n",
        "        index = result_boxes[i]\n",
        "        box = boxes[index]\n",
        "        detection = {\n",
        "            \"class_id\": class_ids[index],\n",
        "            \"class_name\": CLASSES[class_ids[index]],\n",
        "            \"confidence\": scores[index],\n",
        "            \"box\": box,\n",
        "            \"scale\": scale,\n",
        "        }\n",
        "        detections.append(detection)\n",
        "        label = f\"{CLASSES[class_ids[index]]} ({scores[index]:.2f})\"\n",
        "        color = colors[class_ids[index]]\n",
        "        cv2.rectangle(original_image,\n",
        "                      (round(box[0] * scale), round(box[1] * scale)),\n",
        "                      (round((box[0] + box[2]) * scale), round((box[1] + box[3]) * scale)),\n",
        "                       color,\n",
        "                       2)\n",
        "        cv2.putText(original_image,\n",
        "                    label,\n",
        "                    (round(box[0] * scale) - 10, round(box[1] * scale) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5,\n",
        "                    color,\n",
        "                    2)\n",
        "\n",
        "    # Display the image with bounding boxes\n",
        "    # cv2.imshow(\"image\", original_image)\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()\n",
        "    cv2.imwrite(\"output.jpg\", original_image)\n",
        "\n",
        "    return detections\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model\", default=\"yolov8n.onnx\", help=\"Input your ONNX model.\")\n",
        "    parser.add_argument(\"--img\", default=\"bus.jpg\", help=\"Path to input image.\")\n",
        "    parser.add_argument(\"--img\", default=\"bus.jpg\", help=\"Path to input image.\")\n",
        "    parser.add_argument(\"--img_size\", default=640, type=int, help=\"Image size for inference.\")\n",
        "    args = parser.parse_args()\n",
        "    main(args.model, args.img, args.img_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
